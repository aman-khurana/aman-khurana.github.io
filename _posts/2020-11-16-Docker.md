---

---

### Docker

Key

- separate applications from infrastructure



#### Docker Platform

- run applications  in a loosely isolated environment - container
- run many containers on a given host
- lightweight, run directly on host machine's kernel
- Docker provides tools and platform to manage the life-cycle of a container
- How it works?
  - Develop applications and its supporting components using containers
  - container becomes the unit for distributing and testing the application
  - deploy the application into the production environment as a container or an orchestrated service.

#### Docker Engine

Docker engine is a client server application with the following components

- server - type of long running program called a daemon process
  - ` dockerd` command
- REST API which specifies interfaces that programs can use to talk to the daemon and instruct it what to do
- CLI client 
  - `docker` command



## **Docker Tutorial**

- Hypervisor used to run multiple OS on the same hardware
  - makes virtual machines possible
- Docker uses the OS kernel
  - Docker Container for one OS kernel can work with any OS which share the same kernel
  - or VM machine which runs an OS with the same kernel
- Docker container packages an application with its libraries and dependencies
- Docker is a layer above OS
- Docker containers are lightweight
- Docker hubs of applications found on dockerhub
  - these images are published by companies
  - download and install image
  - run like `docker run mongodb`



#### Container vs Image

- Image
  - package or template 
  - used to create one or more containers
- Container
  - running instances of images
  - isolated

#### Getting Started

**Docker Commands**

1. run
   - `docker run nginx`
   - starts a container, runs instance of nginx 
2. docker ps
   - lists the running containers
   - `-a` - includes previous exited container as well
3. docker stop `name` or `id`
4. docker rm
   - removes an exited container
5. docker images
   - list of available images and their sizes
6. docker rmi `image`
   - remove an image
   - make sure no container is running using that image
7. docker pull `imagename`
   - downloads the image locally
8. docker run ubuntu
   - after `docker run ubuntu` , the `docker ps` command doesn't show it as running
   - it shows in the exited containers
   - reason  - since there is no active process inside the container, it exits automatically
   - `docker run ubuntu sleep 5`
     - runs a sleep command for 5 sec
     - example of running a command when we run the container
9. executing a command on a running container
   - `docker exec CONTAINER_NAME <command>`
   - `docker exec randomName cat /etc/hosts`
     - lists the hosts file
10. run - attach and detach
    - `-d` runs in detach mode, console is available for other commands
    - `docker run -d simple-app` 
    - without `-d` option runs in foreground
    - To attach back
      - docker attach CONTAINER_ID
        - first few chars of the id is sufficient as long as it is different





**Docker run command**

- Tag
  - `docker run redis` - by default the `latest`tag
  - `docker run redis:4.0`
    - called as tag
    - the list of available tags on dockerhub
- STDIN
  - stdin of the host machine not attached to the docker terminal
  - `-i` 
    - enables the interactive mode on the container
  - `-t`
    - attaches the terminal
  - `-it` 
- Port mapping/publishing 
  - docker engine runs on host
  - containers runs on top of the docker engine
  - to map ports of the container to the host use the `-p`option
  - `docker run -p 80:5000 webapp`
    - this maps the hosts port 80 to the post 5000 on the container
    - to access the webapp - `host-ip:80`
- Volume mapping
  - how to persist data if the container is removed
  - `docker -v /dir/in/host:/data/dir/inside/container mysql`
  - the host dir is mounted inside the docker container, now if the container is destroyed, the data still persists on the host
- Inspect Container
  - `docker inspect container_name`
  - returns details of a container in json format
- Logs of the container
  - `docker logs container_name`
  - returns output logs written to the stdout of the container

**Environment Variables**

- to set environment variable inside a container
- `docker run -e VARIABLE_NAME=VALUE webapp`
- To check set environment variables inside a running container
  - `docker inspect container_name`
  - check the `ENV` property in the json

**Docker Images**

- To create own custom images , following steps are followed
  - Create Dockerfile, each line has the following format
  - Format -  COMMAND ARGUMENT
  - First command should be `FROM` followed by `OS_NAME` like `UBUNTU`
  - followed by any commands to be run `RUN apt update`
  - `ENTRYPOINT` followed by a command specifies the command to be run when the image's instance (container ) is created
  - Build process has a layered architecture
    - Each command in the docker file builds up on the previous layer
    - Each layer is cached, making rebuilds faster
  - build command
    - `docker build -t tagName ./context` ; builds the image with the tag name
    - `Dockerfile` in context is used; context can be a web url, like a github repo
    - `-f` is used to specify a Dockerfile explicitly
    - `docker push tag_name` ; this command pushes the image to the docker hub

**CMD vs ENTRYPOINT**

- Containers are meant to run a specific task or process
  - host instance of a web server or a application server, database
  - once tasks complete, the container exits
- `docker run ubuntu` . exits immediately as there is nothing to run which is specified
  - ubuntu image by default starts the "bash", which listens for inputs from the container
  - since there is no running terminal, bash exits and therefore the container exits 
- What defines what will run inside a container?
  - `CMD ["nginx"]`  
- another way to specify command
  - `docker run ubuntu [COMMAND]`
- Or build new image on top of the current image, and specify the CMD
  - `CMD COMMAND_NAME` or `CMD ["command"."param"]` like `CMD ["sleep", "5"]`
- ENTRYPOINT
  - the command specified in ENTRYPOINT can be appended by arguments while running
  - `docker run ubuntu 10`
  - CMD command can be used to give default arguments to ENTRYPOINT commands if no arguments specified at runtime
  - both CMD and ENTRYPOINT should be in json format
  - if ENTRYPOINT has to be changed at runtime, `--entrypoint new_command` can be added to the run command



**Networking**


- The default network is brodge
- when network = host, the ports are common for all the containers, cannot reuse the same ports for different containers
- creating a new network
  - `docker network create --driver bridge --subnet 182.18.0.0/16 custom-isolated-network`
- docker maintains a private dns server
  - containers can resolve each other by name, using private ips is not required

**Docker Storage**

When Docker is installed on a system

- stored on
- `var/lib/docker`
  - `volumes`
  - `images`
  - `containers`
  - ..

`docker volume create new_volume`

- creates `new_volume` under the volumes folder

Mapping data volume to a folder inside container (to persist data after container is destroyed)

- `docker run -v new_volume:/var/lib/mysql mysql`
- maps new volume to the folder inside mysql container
- if new volume is not created, docker will create the volume and mount the volume
- can also mount locations which are not inside volumes folder, need to specify full path for the same (called as binding)
- new way to give the command
  - `--mount type=bind,source=/data/mysql,target=/var/lib/mysql`



Docker uses storage drivers to maintain the layered architecture, copy files on write, manage mounts, etc

- with ubuntu, default storage driver is AUFS, based on OS
- different storage drivers provide different performances, etc

When a container is created. a container layer is created on top of the image layers

- container layer is READ WRITE
- image layers are READ ONLY



**Docker Compose**

- docker-compose.yml file
- specify all the containers that are to be run, with their networking and order of running by depends_on property
- 3 versions, specify version in the start of the file as `version: 2`
- specify containers to be run, with the desired name as the key
  - has properties like image, build(if image is not registered, pass the folder dir to build property)
  - ports, links
    - specify the port publishing, and link the containers by using names
  - in version 3,  docker creates a new network and all the containers can access each other by name, no need to create links
- In version 3, can also add `networks` property, the networks property allows us to create sub networks and assign containers to list of these networks



**Docker Registry**

- central repository of docker images
- name format:
  - `username/image_name`
  - `nginx/nginx` = `nginx`
- By default images are stored on dockers default public registry
- Private registries can be used, need to login using `docker login private_registry.io`
- Then we can run
  - `docker run private_registry.io/apps/internal-app`
  - by default the registry is `docker.io`
-  AWS, etc provide a private registry
- Deploy a private registry
  - registry is an image provided by docker
  - can run the registry image, to create a private registry
    - `docker run -d -p 5000:5000 --name registry registry:2`
  - can tag image with the private url like
    - `docker image tag my-img localhost:5000/my-img`
    - tagging the `my-img` to the local registry (!)
  - push to the local registry like
    - `docker push localhost:5000/my-img`
    - pull likewise
  - can provide network ip instead of the localhost, if pulling at a machine different from the host



**Docker Engine**



- Three Components
  - Docker CLI
  - REST API
  - Docker Daemon

- Docker CLI can be on a different host
  - `docker -H=address.of.remote.host:port_num run nginx`
- Can restrict host resources available to the container
  - `docker run --cpus=.5 ubuntu`  ; 50% cpus available
  - `docker run --memory=100m ubuntu` ; 100 MB available



**Container Orchestration**

- Tools and scripts to manage host containers in a production environment

- Using a single command, run and manage containers on multiple hosts
- Some Orchestration solutions can automate scaling hosts and containers
  - also other advanced features
- Solutions
  - Docker Swarm
    - simple, easy to setup
    - lacks autoscaling features
  - Kubernetes
    - Bit difficult to set up
    - Most popular
    - Supported by all cloud providers
  - Mesos
    - difficult to set up
    - provides a lot of features



**Docker Swarm**

- combine multiple hosts into a single cluster
- multiple hosts, one swarm manager
- docker swarm init  ; initializes manager
  - outputs command to be run on other nodes to join the cluster
- `docker service create` command creates a service
  - can specify what containers to run
  - number of replicas 
  - the service runs the container across clusters
  - the create command to be run on swarm manager
  - the options to the `create` command is the same as `run` command
- Other features like configuring multiple managers, etc.

